[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Henok Dawite",
    "section": "",
    "text": "I am pursuing a BA in Computer Science from Pomona College. I am learning to apply computational thinking and programming skills to solve complex problems and have a passion for technology and innovation. I am fluent in Amharic and English, have limited proficiency in Spanish, and enjoy learning new languages and cultures. I am a driven, adaptable, and collaborative individual who values teamwork, creativity, and excellence."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Valentines Day Gifts.html",
    "href": "Valentines Day Gifts.html",
    "title": "Valentines Day Gifts",
    "section": "",
    "text": "Attaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "Meteorite falls.html",
    "href": "Meteorite falls.html",
    "title": "Meteorite falls",
    "section": "",
    "text": "suppressMessages(library(ggplot2))\nsuppressMessages(library(dplyr))\n\n# Load dataset\nmeteorites &lt;- read.csv(\"meteorites.csv\")\n\n# Data preparation\nmeteorites_clean &lt;- meteorites |&gt;\n  filter(!is.na(fall)) |&gt;\n  group_by(fall) |&gt;\n  summarise(count = n(), .groups = 'drop')\n\n# Plot\nggplot(meteorites_clean, aes(x = fall, y = count, fill = fall)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Meteorite Falls vs. Finds\",\n       x = \"Event Type (Fall = Observed Fall, Find = Later Discovery)\",\n       y = \"Number of Meteorites\") +\n  theme_minimal()"
  },
  {
    "objectID": "Project 2.html",
    "href": "Project 2.html",
    "title": "Analysis of Netflix Movies and TV Shows",
    "section": "",
    "text": "library(tidyverse)\nlibrary(stringr)\nlibrary(ggplot2)\n\n# Load the dataset\nnetflix_data &lt;- read.csv(\"netflix_titles 2.csv\", stringsAsFactors = FALSE)\n\n# Data Cleaning\nnetflix_data &lt;- netflix_data %&gt;%\n  mutate(\n    date_added = as.Date(date_added, format=\"%B %d, %Y\"),\n    title = as.character(title)\n  )\n\n\n# Extract year from date_added for visualization\nnetflix_data$year_added &lt;- str_extract(netflix_data$date_added, \"\\\\d{4}\")\n\nnetflix_data_clean &lt;- netflix_data %&gt;% filter(!is.na(year_added))\n\n# Number of titles per year\np1 &lt;- ggplot(netflix_data_clean, aes(x = year_added)) +\n  geom_bar(fill = \"steelblue\", color = \"black\", width = 0.8) +\n  labs(title = \"Number of Titles Added Per Year\", x = \"Year\", y = \"Count\")\n\nprint(p1)\n\n\n\n\n\n\n\n\nThis is a bar chart that indicates how many titles were added to the Netflix library each year. If we determine that more titles were added one year than the next, we can deduce whether Netflix was in a position to try to reduce titles at one point due to business constraints or, conversely, in a stable position to assess market forces or consumer demand and expand availability.\n\n# Count the number of words in each description for visualization\nnetflix_data$word_count &lt;- str_count(netflix_data$description, \"\\\\w+\")\n\n# Average word count in description by type\np2 &lt;- ggplot(netflix_data, aes(x = type, y = word_count, fill = type)) +\n  geom_boxplot() +\n  labs(title = \"Word Count in Description by Type\", x = \"Type\", y = \"Word Count\") +\n  scale_fill_brewer(palette = \"Set3\")\n\nprint(p2)\n\n\n\n\n\n\n\n\nThis box plot displays the distribution of word counts in content descriptions, categorized by the types that are movies and TV shows. According to the figure, TV shows often have shorter descriptions (around 20–30 words), but movies have lengthier descriptions (about 40–50 words on average). This implies that because movies are stand-alone works of content, they may need more thorough explanations to condense their stories and concepts. TV shows, on the other hand, may employ briefer summaries and concentrate on more general themes entice people to watch a series.\n\n# Split titles into words and count most common words\nnetflix_data$word_after_the &lt;- str_extract(netflix_data$title, \"(?&lt;=The )\\\\w+\")\n\nword_after_the_counts &lt;- netflix_data$word_after_the %&gt;%\n  na.omit() %&gt;%                 \n  table() %&gt;%                   \n  as.data.frame() %&gt;%\n  rename(word = \".\", count = \"Freq\") %&gt;%\n  arrange(desc(count)) %&gt;%\n  head(10)                             \n\np3 &lt;- ggplot(word_after_the_counts, aes(x = reorder(word, count), y = count, fill = count)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  coord_flip() +\n  labs(title = \"Top 10 Words Following 'The' in Netflix Titles\", x = \"Word\", y = \"Count\") +\n  scale_fill_gradient(low = \"moccasin\", high = \"darkorange\") +\n  theme(legend.position = \"none\") \n\nprint(p3)\n\n\n\n\n\n\n\n\nThis horizontal bar chart showcases the ten most common words that immediately follow ‘The’ in Netflix titles. This chart analyzes the frequency of words that commonly follow the word “The” in titles on Netflix. The most frequent word is “Last,” followed by “Movie,” “Series,” “Great,” “Story,” “Legend,” “Beginning,” “New,” “Little,” and “Devil.” This data suggests that Netflix titles often use these words to create intrigue or convey the theme of the content. For instance, words like “Last,” “Great,” and “Legend” might indicate titles with epic or significant narratives, while “Movie” and “Series” are straightforward descriptors of the format.\nData Source:\nAccessed via: TidyTuesday GitHub page\nOriginal Source: Kaggle"
  },
  {
    "objectID": "Project 3.html",
    "href": "Project 3.html",
    "title": "Free Throw Rate and Tournament Odds",
    "section": "",
    "text": "Full Context of Problem\nThis project investigates whether NCAA Division I men’s basketball teams that make the tournament tend to get to the free throw line more often than those that don’t. The data set used (cbb.csv) includes team-level performance statistics from a full season, including each team’s free throw rate (FTR). This is defined as free throw attempts per field goal attempt. To examine this, we create a new variable, made_tourney, that categorizes teams as either having qualified for the NCAA tournament or not.\nThe null hypothesis is that there is no real difference in free throw rate between teams that make the tournament. For those that don’t, any observed difference is due to random chance. The alternative hypothesis is that teams who qualify for the tournament tend to have higher free throw rates. This relationship is worth looking into because a higher FTR often reflects physicality, aggressiveness, or the ability to draw fouls. Those traits may or may not contribute to team success leading up to the tournament. We begin by visualizing the distribution of FTR across both groups, and then conduct a permutation test to assess whether the observed difference is statistically significant.\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(infer)\n\n\ncbb &lt;- read_csv(\"cbb.csv\") |&gt; clean_names()\n\n# create a binary variable for whether the team made the tournament or not\ncbb &lt;- cbb |&gt; \n  mutate(made_tourney = if_else(postseason %in% c(\"2ND\", \"Champions\", \"E8\", \"F4\", \"R32\", \"R64\", \"R68\", \"S16\"), \"yes\", \"no\"))\n\n# keep only relevant columns\ncbb_filtered &lt;- cbb |&gt; \n  filter(made_tourney %in% c(\"yes\", \"no\")) |&gt; \n  select(ftr, made_tourney)\n\nVisualize Group Differences\n\n# create a boxplot to compare the distribution of Free Throw Rate (FTR)\n# between tournament and non-tournament teams\nggplot(cbb_filtered, aes(x = made_tourney, y = ftr, fill = made_tourney)) +\n  geom_boxplot() +\n  labs(\n    title = \"Free Throw Rate by Tournament Status\",\n    x = \"Made NCAA Tournament\",\n    y = \"Free Throw Rate (FTA/FGA)\")\n\n\n\n\n\n\n\n\nAbout Box Plot\nThis box plot compares Free Throw Rate (FTR) between teams that made the NCAA tournament and those that didn’t. It shows that tournament teams generally have a higher median FTR, and their overall distribution is slightly shifted upward. This visual gives an early indication that teams reaching the tournament may be more likely to draw fouls and get to the free throw line.\n\n# calculate the observed difference in mean FTR between the two groups\nobs_diff &lt;- cbb_filtered |&gt; \n  specify(ftr ~ made_tourney) |&gt; \n  calculate(stat = \"diff in means\", order = c(\"yes\", \"no\"))\n\nobs_diff\n\nResponse: ftr (numeric)\nExplanatory: made_tourney (factor)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1  1.35\n\n\nRun Permutation Test\n\n# simulate the null distribution by randomly permuting group labels 1000 times\nset.seed(42)\nperm_results &lt;- cbb_filtered |&gt; \n  specify(ftr ~ made_tourney) |&gt; \n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 1000, type = \"permute\") |&gt; \n  calculate(stat = \"diff in means\", order = c(\"yes\", \"no\"))\n\nPlot Null Distribution\n\n# create a histogram to visualize the null distribution of permuted differences\n# and overlay the observed difference as a red dashed line\nggplot(perm_results, aes(x = stat)) +\n  geom_histogram(binwidth = 0.05, fill = \"skyblue\", color = \"black\") +\n  geom_vline(xintercept = obs_diff$stat, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Null Distribution of Free Throw Rate Differences\",\n    x = \"Difference in Mean FTR (Tournament - Non-Tournament)\",\n    y = \"Frequency\")\n\n\n\n\n\n\n\n\nAbout Histogram\nThis graph shows simulated differences in Free Throw Rate, assuming no real relationship exists. The red dashed line represents the actual observed difference between tournament and non-tournament teams, which falls far to the right of most simulated values. This would suggest that the result is unlikely due to chance.\n\n# calculate p-value\np_val &lt;- mean(abs(perm_results$stat) &gt;= abs(obs_diff$stat))\np_val\n\n[1] 0\n\n\nConclusion\nUltimately, my permutation test found that teams that make the NCAA tournament have a statistically significantly higher Free Throw Rate than teams that do not, with a p-value of less than 0.001, meaning this difference is not due to chance. I found this by calculating the means of both populations’ free throw rates and performing a permutation test of my own, where I randomly shuffled the labels of whether or not teams made the NCAA tournament 1,000 times, hypothesizing that there was no association between tournament outcome and Free Throw Rate. I then plotted the observed difference based on iteration. I found that the actual difference in means I calculated was far more extreme than any of the differences created within my simulation—effectively echoing that making it to the free throw line more often is a characteristic of teams that make the tournament over those that do not.\nData Source:\nAccessed via: https://www.kaggle.com/\nOriginal Source: Kaggle"
  },
  {
    "objectID": "Project 3.html#load-libraries",
    "href": "Project 3.html#load-libraries",
    "title": "Free Throw Rate and Tournament Success",
    "section": "",
    "text": "library(tidyverse)\nlibrary(janitor)"
  },
  {
    "objectID": "Project 3.html#read-and-prepare-data",
    "href": "Project 3.html#read-and-prepare-data",
    "title": "Free Throw Rate and Tournament Success",
    "section": "2 2. Read and Prepare Data",
    "text": "2 2. Read and Prepare Data\n\ncbb &lt;- read_csv(\"cbb.csv\") |&gt; clean_names()\n\ncbb &lt;- cbb |&gt; \n  mutate(made_tourney = if_else(postseason %in% c(\"2ND\", \"Champions\", \"E8\", \"F4\", \"R32\", \"R64\", \"R68\", \"S16\"), \"yes\", \"no\"))"
  },
  {
    "objectID": "Project 3.html#explore-the-data",
    "href": "Project 3.html#explore-the-data",
    "title": "Free Throw Rate and Tournament Success",
    "section": "3 3. Explore the Data",
    "text": "3 3. Explore the Data\n\ncbb |&gt; \n  ggplot(aes(x = made_tourney, y = ftr, fill = made_tourney)) +\n  geom_boxplot() +\n  labs(\n    title = \"Free Throw Rate by Tournament Status\",\n    x = \"Made NCAA Tournament\",\n    y = \"Free Throw Rate (FTA/FGA)\") +\n  theme_minimal()"
  },
  {
    "objectID": "Project 3.html#observed-statistic",
    "href": "Project 3.html#observed-statistic",
    "title": "Free Throw Rate and Tournament Success",
    "section": "4 4. Observed Statistic",
    "text": "4 4. Observed Statistic\n\nobserved_diff &lt;- cbb |&gt; \n  group_by(made_tourney) |&gt; \n  summarize(mean_ftr = mean(ftr, na.rm = TRUE)) |&gt; \n  pivot_wider(names_from = made_tourney, values_from = mean_ftr) |&gt; \n  mutate(diff = yes - no) |&gt; \n  pull(diff)\n\nobserved_diff\n\n[1] 1.349134"
  },
  {
    "objectID": "Project 3.html#define-permutation-function",
    "href": "Project 3.html#define-permutation-function",
    "title": "Free Throw Rate and Tournament Success",
    "section": "5 5. Define Permutation Function",
    "text": "5 5. Define Permutation Function\n\npermute_diff &lt;- function(data) {\n  shuffled &lt;- sample(data$made_tourney)\n  perm_means &lt;- data |&gt; \n    mutate(shuffled_group = shuffled) |&gt; \n    group_by(shuffled_group) |&gt; \n    summarize(mean_ftr = mean(ftr, na.rm = TRUE), .groups = \"drop\")\n\n  if (!all(c(\"yes\", \"no\") %in% perm_means$shuffled_group)) {\n    return(NA_real_)\n  }\n\n  yes_mean &lt;- perm_means |&gt; filter(shuffled_group == \"yes\") |&gt; pull(mean_ftr)\n  no_mean &lt;- perm_means |&gt; filter(shuffled_group == \"no\") |&gt; pull(mean_ftr)\n\n  return(yes_mean - no_mean)\n}"
  },
  {
    "objectID": "Project 3.html#run-simulation",
    "href": "Project 3.html#run-simulation",
    "title": "Free Throw Rate and Tournament Success",
    "section": "6 6. Run Simulation",
    "text": "6 6. Run Simulation\n\nset.seed(42)\nperm_diffs &lt;- map_dbl(1:1000, ~permute_diff(cbb))\nperm_diffs &lt;- perm_diffs[!is.na(perm_diffs)]"
  },
  {
    "objectID": "Project 3.html#visualize-null-distribution",
    "href": "Project 3.html#visualize-null-distribution",
    "title": "Free Throw Rate and Tournament Success",
    "section": "7 7. Visualize Null Distribution",
    "text": "7 7. Visualize Null Distribution\n\ntibble(perm_diffs) |&gt; \n  ggplot(aes(x = perm_diffs)) +\n  geom_histogram(binwidth = 0.03, fill = \"skyblue\", color = \"black\") +\n  geom_vline(xintercept = observed_diff, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Permutation Test: Free Throw Rate Differences\",\n    x = \"Difference in Mean FTR (Tournament - Non-Tournament)\",\n    y = \"Frequency\") +\n  theme_minimal()"
  },
  {
    "objectID": "Project 3.html#calculate-p-value",
    "href": "Project 3.html#calculate-p-value",
    "title": "Free Throw Rate and Tournament Success",
    "section": "8 8. Calculate P-value",
    "text": "8 8. Calculate P-value\n\np_value &lt;- mean(abs(perm_diffs) &gt;= abs(observed_diff))\np_value\n\n[1] 0"
  },
  {
    "objectID": "Project 3.html#full-context-of-problem",
    "href": "Project 3.html#full-context-of-problem",
    "title": "Free Throw Rate and Tournament Odds",
    "section": "",
    "text": "This project investigates whether NCAA Division I men’s basketball teams that make the tournament tend to get to the free throw line more often than those that don’t. The data set used (cbb.csv) includes team-level performance statistics from a full season, including each team’s free throw rate (FTR). This is defined as free throw attempts per field goal attempt. To examine this, we create a new variable, made_tourney, that categorizes teams as either having qualified for the NCAA tournament or not.\nThe null hypothesis is that there is no real difference in free throw rate between teams that make the tournament. For those that don’t, any observed difference is due to random chance. The alternative hypothesis is that teams who qualify for the tournament tend to have higher free throw rates. This relationship is worth looking into because a higher FTR often reflects physicality, aggressiveness, or the ability to draw fouls. Those traits may or may not contribute to team success leading up to the tournament. We begin by visualizing the distribution of FTR across both groups, and then conduct a permutation test to assess whether the observed difference is statistically significant.\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(infer)\n\n\ncbb &lt;- read_csv(\"cbb.csv\") |&gt; clean_names()\n\n# create a binary variable for whether the team made the tournament or not\ncbb &lt;- cbb |&gt; \n  mutate(made_tourney = if_else(postseason %in% c(\"2ND\", \"Champions\", \"E8\", \"F4\", \"R32\", \"R64\", \"R68\", \"S16\"), \"yes\", \"no\"))\n\n# keep only relevant columns\ncbb_filtered &lt;- cbb |&gt; \n  filter(made_tourney %in% c(\"yes\", \"no\")) |&gt; \n  select(ftr, made_tourney)"
  },
  {
    "objectID": "Project 3.html#visualize-group-differences",
    "href": "Project 3.html#visualize-group-differences",
    "title": "Free Throw Rate and Tournament Odds",
    "section": "2 Visualize Group Differences",
    "text": "2 Visualize Group Differences\n\n# create a boxplot to compare the distribution of Free Throw Rate (FTR)\n# between tournament and non-tournament teams\nggplot(cbb_filtered, aes(x = made_tourney, y = ftr, fill = made_tourney)) +\n  geom_boxplot() +\n  labs(\n    title = \"Free Throw Rate by Tournament Status\",\n    x = \"Made NCAA Tournament\",\n    y = \"Free Throw Rate (FTA/FGA)\")"
  },
  {
    "objectID": "Project 3.html#about-box-plot",
    "href": "Project 3.html#about-box-plot",
    "title": "Free Throw Rate and Tournament Odds",
    "section": "3 About Box Plot",
    "text": "3 About Box Plot\nThis box plot compares Free Throw Rate (FTR) between teams that made the NCAA tournament and those that didn’t. It shows that tournament teams generally have a higher median FTR, and their overall distribution is slightly shifted upward. This visual gives an early indication that teams reaching the tournament may be more likely to draw fouls and get to the free throw line.\n\n# calculate the observed difference in mean FTR between the two groups\nobs_diff &lt;- cbb_filtered |&gt; \n  specify(ftr ~ made_tourney) |&gt; \n  calculate(stat = \"diff in means\", order = c(\"yes\", \"no\"))\n\nobs_diff\n\nResponse: ftr (numeric)\nExplanatory: made_tourney (factor)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1  1.35"
  },
  {
    "objectID": "Project 3.html#run-permutation-test",
    "href": "Project 3.html#run-permutation-test",
    "title": "Free Throw Rate and Tournament Odds",
    "section": "4 Run Permutation Test",
    "text": "4 Run Permutation Test\n\n# simulate the null distribution by randomly permuting group labels 1000 times\nset.seed(42)\nperm_results &lt;- cbb_filtered |&gt; \n  specify(ftr ~ made_tourney) |&gt; \n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 1000, type = \"permute\") |&gt; \n  calculate(stat = \"diff in means\", order = c(\"yes\", \"no\"))"
  },
  {
    "objectID": "Project 3.html#plot-null-distribution",
    "href": "Project 3.html#plot-null-distribution",
    "title": "Free Throw Rate and Tournament Odds",
    "section": "5 Plot Null Distribution",
    "text": "5 Plot Null Distribution\n\n# create a histogram to visualize the null distribution of permuted differences\n# and overlay the observed difference as a red dashed line\nggplot(perm_results, aes(x = stat)) +\n  geom_histogram(binwidth = 0.05, fill = \"skyblue\", color = \"black\") +\n  geom_vline(xintercept = obs_diff$stat, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Null Distribution of Free Throw Rate Differences\",\n    x = \"Difference in Mean FTR (Tournament - Non-Tournament)\",\n    y = \"Frequency\")"
  },
  {
    "objectID": "Project 3.html#about-histogram",
    "href": "Project 3.html#about-histogram",
    "title": "Free Throw Rate and Tournament Odds",
    "section": "6 About Histogram",
    "text": "6 About Histogram\nThis graph shows simulated differences in Free Throw Rate, assuming no real relationship exists. The red dashed line represents the actual observed difference between tournament and non-tournament teams, which falls far to the right of most simulated values. This would suggest that the result is unlikely due to chance.\n\n# calculate p-value\np_val &lt;- mean(abs(perm_results$stat) &gt;= abs(obs_diff$stat))\np_val\n\n[1] 0"
  },
  {
    "objectID": "Project 3.html#conclusion",
    "href": "Project 3.html#conclusion",
    "title": "Free Throw Rate and Tournament Odds",
    "section": "7 Conclusion",
    "text": "7 Conclusion\nUltimately, my permutation test found that teams that make the NCAA tournament have a statistically significantly higher Free Throw Rate than teams that do not, with a p-value of less than 0.001, meaning this difference is not due to chance. I found this by calculating the means of both populations’ free throw rates and performing a permutation test of my own, where I randomly shuffled the labels of whether or not teams made the NCAA tournament 1,000 times, hypothesizing that there was no association between tournament outcome and Free Throw Rate. I then plotted the observed difference based on iteration. I found that the actual difference in means I calculated was far more extreme than any of the differences created within my simulation—effectively echoing that making it to the charity stripe more often is a characteristic of teams that make the tournament over those that do not."
  },
  {
    "objectID": "Project4.html",
    "href": "Project4.html",
    "title": "Havasupai Tribe v. Arizona Board of Regents",
    "section": "",
    "text": "Introduction\nBack in the early 2000s, the Havasupai Tribe—a small Indigenous community living in the Grand Canyon—trusted researchers at Arizona State University (ASU) with their blood samples. They believed the researchers were going to use the samples to help study diabetes, which was a growing concern in their community. But those samples weren’t just used for diabetes studies. Without the tribe’s knowledge or consent, the blood was later used for research on schizophrenia, inbreeding, and human migration (Van Assche et al., 2013; Harmon, 2010). The tribe was shocked and devastated.\nThe situation eventually led to a lawsuit known as Havasupai Tribe v. Arizona Board of Regents. The core issue was that the research had crossed boundaries the tribe never agreed to, raising serious concerns about consent and respect. According to Van Assche et al. (2013), the forms may have allowed it on paper, but the tribe was never truly informed. What followed sparked broader questions about how researchers treat the people behind the data. Let’s now take a closer look at the ethical concerns raised by this case.\nDid the Havasupai truly give permission for how their blood samples were used?\nTechnically, the researchers at ASU did have a consent form. It included broad language that mentioned “behavioral/medical disorders.” That’s what they later pointed to as permission for using the data in a wider range of studies. But what happened in practice was very different. Most Havasupai members didn’t read or speak English fluently, and the research was explained to them verbally. They were told it was a diabetes study, nothing more (Van Assche et al., 2013).\nSo yes, there was a permission structure on paper. But ethically, that permission meant nothing. I believe the researchers didn’t follow through on making sure participants truly understood what they were agreeing to. As a result, the permission structure wasn’t really followed in any meaningful way.\nWas the Havasupai Tribe’s genetic data kept private, or was it shared beyond what they agreed to?\nFrom what I found in the sources, there’s no indication that the genetic data from the Havasupai Tribe was ever made publicly available in the way we usually think about open datasets. But that doesn’t mean the data wasn’t shared. In fact, some of the samples were passed on to other researchers outside of ASU, and at least one report said some were lost entirely due to a freezer malfunction (Van Assche et al., 2013). \nEven if the data wasn’t posted online or made downloadable, the fact that it was shared without consent feels like a breach of privacy and respect. I don’t think it matters whether the data was technically “public” or not. What matters is that it was out of the tribe’s control, and to me, that feels just as harmful.\nWere the blood samples used in ways that went beyond what the tribe had agreed to?\nAbsolutely. The tribe agreed to a diabetes study. That’s what they were told, and that’s what they wanted to help with. But instead, their samples were used for studies on things like schizophrenia and human migration. One study even suggested that the Havasupai people had migrated from Asia, which directly contradicted their spiritual belief that they originated in the Grand Canyon (Harmon, 2010).\nI think it’s one of the clearest examples of what can go wrong when researchers stretch the boundaries of what participants agreed to. The way the data was used left deep scars on the tribe. This all disrupted how they saw themselves, and fractured their relationship to their past.\nEven if the samples were anonymized, could the research still harm the Havasupai as a group?\nThe researchers removed names from the samples. So technically, they were anonymized. But that didn’t mean the tribe wasn’t harmed. The studies clearly focused on the Havasupai as a group. And as Van Assche et al. (2013) explain, removing names doesn’t prevent what they call “dignitary harm,” the kind of damage that happens when a group’s identity and values are disrespected.\nFor the Havasupai, the blood samples weren’t just data to them as is also considered sacred. Using them in ways the tribe didn’t approve of was more than a privacy issue. As I mentioned earlier, some of the samples had already been lost or handed over to outside researchers.\nConclusion\nUltimately, we need to make sure that consent is culturally appropriate and that we do not go beyond what participants consented to. We need to acknowledge positionality and use the research to benefit the community. We need to understand that data science is about human experience, not just data.\nReferences\nVan Assche, K., Gutwirth, S., & Sterckx, S. (2013). Protecting Dignitary Interests of Biobank Research Participants: Lessons from Havasupai Tribe v Arizona Board of Regents. Law, Innovation and Technology, 5(1), 54–84. https://doi.org/10.5235/17579961.5.1.54\nHarmon, A. (2010). Indian Tribe Wins Fight to Limit Research of Its DNA. The New York Times. https://www.nytimes.com/2010/04/22/us/22dna.html"
  },
  {
    "objectID": "Project4.html#introduction",
    "href": "Project4.html#introduction",
    "title": "Havasupai Tribe v. Arizona Board of Regents",
    "section": "",
    "text": "Back in the early 2000s, the Havasupai Tribe—a small Indigenous community living in the Grand Canyon—trusted researchers at Arizona State University (ASU) with their blood samples. They believed the researchers were going to use the samples to help study diabetes, which was a growing concern in their community. But those samples weren’t just used for diabetes studies. Without the tribe’s knowledge or consent, the blood was later used for research on schizophrenia, inbreeding, and human migration (Van Assche et al., 2013; Harmon, 2010). The tribe was shocked and devastated.\nThis situation eventually led to a lawsuit titled Havasupai Tribe v. Arizona Board of Regents. More than a legal battle, I see it as a turning point that raised serious ethical questions about data use, informed consent, and the responsibilities researchers have to the communities they study. Using ideas from data feminism and the Data Values and Principles manifesto, I will explore what went wrong and what I think we can learn from it."
  },
  {
    "objectID": "Project4.html#what-is-the-permission-structure-for-using-the-data-was-it-followed",
    "href": "Project4.html#what-is-the-permission-structure-for-using-the-data-was-it-followed",
    "title": "Havasupai Tribe v. Arizona Board of Regents",
    "section": "What is the permission structure for using the data? Was it followed?",
    "text": "What is the permission structure for using the data? Was it followed?\nTechnically, the researchers at ASU did have a consent form. It included broad language that mentioned “behavioral/medical disorders.” That’s what they later pointed to as permission for using the data in a wider range of studies. But what happened in practice was very different. Most Havasupai members didn’t read or speak English fluently, and the research was explained to them verbally. They were told it was a diabetes study, nothing more (Van Assche et al., 2013).\nSo yes, there was a permission structure on paper. But ethically, that permission meant nothing. I believe the researchers didn’t follow through on making sure participants truly understood what they were agreeing to. As a result, the permission structure wasn’t really followed in any meaningful way."
  },
  {
    "objectID": "Project4.html#were-the-data-made-publicly-available",
    "href": "Project4.html#were-the-data-made-publicly-available",
    "title": "Havasupai Tribe v. Arizona Board of Regents",
    "section": "Were the data made publicly available?",
    "text": "Were the data made publicly available?\nFrom what I found in the sources, there’s no indication that the genetic data from the Havasupai Tribe was ever made publicly available in the way we usually think about open datasets. But that doesn’t mean the data wasn’t shared. In fact, some of the samples were passed on to other researchers outside of ASU, and at least one report said some were lost entirely due to a freezer malfunction (Van Assche et al., 2013). \nEven if the data wasn’t posted online or made downloadable, the fact that it was shared without consent feels like a breach of privacy and respect. I don’t think it matters whether the data was technically “public” or not. What matters is that it was out of the tribe’s control, and to me, that feels just as harmful."
  },
  {
    "objectID": "Project4.html#is-the-data-being-used-in-unintended-ways-to-the-original-study",
    "href": "Project4.html#is-the-data-being-used-in-unintended-ways-to-the-original-study",
    "title": "Havasupai Tribe v. Arizona Board of Regents",
    "section": "Is the data being used in unintended ways to the original study?",
    "text": "Is the data being used in unintended ways to the original study?\nAbsolutely. The tribe agreed to a diabetes study. That’s what they were told, and that’s what they wanted to help with. But instead, their samples were used for studies on things like schizophrenia and human migration. One study even suggested that the Havasupai people had migrated from Asia, which directly contradicted their spiritual belief that they originated in the Grand Canyon (Harmon, 2010).\nI think it’s one of the clearest examples of what can go wrong when researchers stretch the boundaries of what participants agreed to. The way the data was used left deep scars on the tribe. This all disrupted how they saw themselves, and fractured their relationship to their past."
  },
  {
    "objectID": "Project4.html#is-the-data-identifiable-all-of-it-some-of-it-in-what-way-are-the-data-sufficiently-anonymized-or-old-to-be-free-of-ethical-concerns-is-anonymity-guaranteed",
    "href": "Project4.html#is-the-data-identifiable-all-of-it-some-of-it-in-what-way-are-the-data-sufficiently-anonymized-or-old-to-be-free-of-ethical-concerns-is-anonymity-guaranteed",
    "title": "Havasupai Tribe v. Arizona Board of Regents",
    "section": "Is the data identifiable? All of it? Some of it? In what way? Are the data sufficiently anonymized or old to be free of ethical concerns? Is anonymity guaranteed?",
    "text": "Is the data identifiable? All of it? Some of it? In what way? Are the data sufficiently anonymized or old to be free of ethical concerns? Is anonymity guaranteed?\nThe researchers removed names from the samples. So technically, they were anonymized. But that didn’t mean the tribe wasn’t harmed. The studies clearly focused on the Havasupai as a group. And as Van Assche et al. (2013) explain, removing names doesn’t prevent what they call “dignitary harm,” the kind of damage that happens when a group’s identity and values are disrespected.\nFor the Havasupai, the blood samples weren’t just data to them as is also considered sacred. Using them in ways the tribe didn’t approve of was more than a privacy issue. As I mentioned earlier, some of the samples had already been lost or handed over to outside researchers."
  },
  {
    "objectID": "Project4.html#conclusion",
    "href": "Project4.html#conclusion",
    "title": "Havasupai Tribe v. Arizona Board of Regents",
    "section": "Conclusion",
    "text": "Conclusion\nUltimately, we need to make sure that consent is culturally appropriate and that we do not go beyond what participants consented to. We need to acknowledge positionality and use the research to benefit the community. Ultimately, we need to understand that data science is about human experience, not just data."
  },
  {
    "objectID": "Project4.html#references",
    "href": "Project4.html#references",
    "title": "Havasupai Tribe v. Arizona Board of Regents",
    "section": "References",
    "text": "References\nVan Assche, K., Gutwirth, S., & Sterckx, S. (2013). Protecting Dignitary Interests of Biobank Research Participants: Lessons from Havasupai Tribe v Arizona Board of Regents. Law, Innovation and Technology, 5(1), 54–84. https://doi.org/10.5235/17579961.5.1.54\nHarmon, A. (2010). Indian Tribe Wins Fight to Limit Research of Its DNA. The New York Times. https://www.nytimes.com/2010/04/22/us/22dna.html"
  },
  {
    "objectID": "Project5.html",
    "href": "Project5.html",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "",
    "text": "Introduction\nThis project explores racial disparities in traffic stop outcomes using data from the Stanford Open Policing Project (Pierson et al., 2020). Using SQL to query a MariaDB database, we investigate differences in search rates across multiple cities and dig deeper into patterns within a single city. Our goal is to surface insights into how policing practices differ by race and geography using fully SQL-based data wrangling and R for visualization.\n\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(ggplot2)\nlibrary(scales)\n\n# Establish connection to the traffic database\ncon_traffic &lt;- dbConnect(\n  RMariaDB::MariaDB(),\n  dbname   = \"traffic\",\n  host     = Sys.getenv(\"TRAFFIC_HOST\"),\n  user     = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)\n\n\nComparing Search Rates Across Cities and Races\n\nSELECT\n  city,\n  subject_race,\n  ROUND(100.0 * AVG(CASE WHEN search_conducted THEN 1 ELSE 0 END), 2) AS search_rate\nFROM (\n    SELECT 'Charlotte' AS city, subject_race, search_conducted\n      FROM nc_charlotte_2020_04_01\n      WHERE YEAR(date) BETWEEN 2010 AND 2014\n    UNION ALL\n    SELECT 'Raleigh' AS city, subject_race, search_conducted\n      FROM nc_raleigh_2020_04_01\n      WHERE YEAR(date) BETWEEN 2010 AND 2014\n    UNION ALL\n    SELECT 'Greensboro' AS city, subject_race, search_conducted\n      FROM nc_greensboro_2020_04_01\n      WHERE YEAR(date) BETWEEN 2010 AND 2014\n) AS combined\nGROUP BY city, subject_race\nORDER BY city, search_rate DESC;\n\n\nggplot(race_search, aes(x = reorder(subject_race, -search_rate),\n                        y = search_rate, fill = city)) +\n  geom_col(position = \"dodge\", color = \"black\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(\n    title = \"Search Rates by Race (2010–2014)\",\n    x = \"Race\",\n    y = \"Search Rate (%)\",\n    fill = \"City\"\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\nDescription: This is a plot comparing search rates by race for Charlotte, Raleigh, and Greensboro (all North Carolina cities). Charlotte shows that Black drivers have the highest search rate at around 6.75% compared to just over 2.25% of White drivers; Raleigh is second with almost 3.95% for Blacks and 1.95% for Whites; Greensboro, similar to Charlotte, has about 5.14% for Black people and 2.41% for White people. This alludes to a consistent frame across these three cities that no matter where individuals are stopped, historically Black males and females are searched disproportionately higher—and by a long shot—when pulled over in comparison to their White counterparts. The fact that the three cities are so consistent in their gaps makes it hard to disavow random variance or specific variances in one city’s policing efforts. However, this represents a national problem that indicates there is a systematic difference between how one race is treated against another. Hispanic and Asian drivers tend to float around the middle or lower ends of the extremes; for example, Hispanic drivers have a higher overall search percentage than White drivers but lower than Black drivers.\n\n\nStop Outcomes in Oakland, California\n\nSELECT\n  outcome,\n  COUNT(*) AS count,\n  ROUND(100.0 * COUNT(*) / total.total_count, 2) AS percent\nFROM ca_oakland_2020_04_01,\n     (SELECT COUNT(*) \n     AS total_count FROM ca_oakland_2020_04_01 WHERE outcome IS NOT NULL)\n     AS total\nWHERE outcome IS NOT NULL\nGROUP BY outcome, total.total_count\nORDER BY count DESC;\n\n\nggplot(oakland_outcomes, aes(x = reorder(outcome, -count), y = percent)) +\n  geom_col(fill = \"lightblue\", color = \"black\") +\n  labs(\n    title = \"Stop Outcomes in Oakland (2013-2017)\",\n    x = \"Stop Outcome\",\n    y = \"Percentage of Total Stops\"\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\nDescription: This is the outcome of traffic stops in Oakland, California. For the total number of traffic stops, 52% end in citation, 31% end in warning, and 17% end in arrest. The fact that over half of all traffic stops end in citation shows that the majority of traffic violations are minor in nature, yet Oakland law enforcement officials felt that these actions were egregious enough to render a formal citation. With almost one-third of the actions resulting in a warning, this could either mean that the officers give a lot of warnings based on their discretion or that the action was so minor that a citation would be an overreach; either way, this is a fair amount of leeway given. The most surprising statistic is that 17% end in arrest which means that 1 out of every 6 people gets arrested during a stop. This is a relatively high number for either having a large amount of stops based on reasonable suspicion or, conversely, having an overly aggressive policy towards law enforcement where more arrests are had than in other precincts.\nConclusion: Using SQL and R, we analyzed search rates and stop outcomes across and within cities. We used multiple SQL tables and functions (UNION ALL, ROUND, CASE WHEN, GROUP BY, ORDER BY, WHERE) to handle our wrangling exclusively within the database. This approach allowed us to uncover patterns of racial disparity and enforcement trends across jurisdictions. Our comparison across cities revealed that Black drivers face disproportionately high search rates, while city-level breakdowns like in Oakland showed that most stops result in either citations or warnings, but that arrests are not uncommon. The data were sourced from the Stanford Open Policing Project (Pierson et al., 2020), and the analysis suggests that both the rate and nature of stops vary significantly depending on location and race.\nCitation\nPierson, E., Corbett-Davies, S., & Goel, S. (2020). A large-scale analysis of racial disparities in police stops across the United States. Nature Human Behaviour, 4(7), 736–745. https://doi.org/10.1038/s41562-020-0858-1\nData : Stanford Open Policing Project — https://openpolicing.stanford.edu/data/"
  },
  {
    "objectID": "DS02Prezi.html#title-slide",
    "href": "DS02Prezi.html#title-slide",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Title Slide",
    "text": "Title Slide\nRacial Disparities in Traffic Stop Outcomes\nAn SQL-based Analysis of Stanford Open Policing Project Data\nHenok Dawite\nMay 2025"
  },
  {
    "objectID": "DS02Prezi.html#project-overview",
    "href": "DS02Prezi.html#project-overview",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Project Overview",
    "text": "Project Overview\n\nI used public traffic stop data to explore disparities in policing.\n\nFocused on two things:\n\nHow often people of different races are searched.\n\nWhat typically happens after someone is stopped.\n\n\nThis was done using SQL and basic visual analysis."
  },
  {
    "objectID": "DS02Prezi.html#data-source-cleaning",
    "href": "DS02Prezi.html#data-source-cleaning",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Data Source & Cleaning",
    "text": "Data Source & Cleaning\n\nSource: Stanford Open Policing Project — over 50 million stops\n\nKey Columns: driver_race, search_conducted, stop_outcome, violation\n\nCleaning:\n\nRemoved rows with missing race or outcome\n\nFocused on cities/states with consistent reporting\n\nFiltered down to relevant stop data only"
  },
  {
    "objectID": "DS02Prezi.html#key-questions",
    "href": "DS02Prezi.html#key-questions",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Key Questions",
    "text": "Key Questions\n\nAre some racial groups searched more than others?\n\nDo stop outcomes (like arrest or warning) vary by race?\n\nAre these patterns the same across cities?"
  },
  {
    "objectID": "DS02Prezi.html#findings-search-rates-by-race",
    "href": "DS02Prezi.html#findings-search-rates-by-race",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Findings – Search Rates by Race",
    "text": "Findings – Search Rates by Race\n\nBlack and Hispanic drivers are searched more often than white drivers.\n\nIn many cities, disparities were consistent year-over-year.\n\nIndicates a possible bias in determining probable cause for searches."
  },
  {
    "objectID": "DS02Prezi.html#findings-outcomes-after-stops",
    "href": "DS02Prezi.html#findings-outcomes-after-stops",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Findings – Outcomes After Stops",
    "text": "Findings – Outcomes After Stops\n\nBlack and Hispanic drivers are more likely to be arrested than white drivers.\nWhite drivers are more likely to receive warnings.\nThese patterns persist even when the violation is similar."
  },
  {
    "objectID": "DS02Prezi.html#findings-violation-types",
    "href": "DS02Prezi.html#findings-violation-types",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Findings – Violation Types",
    "text": "Findings – Violation Types\n\nVague violations like “equipment” or “other” are disproportionately cited for Black drivers.\nThese are harder to contest and give more discretion to officers.\nThis may reflect over-policing for minor, subjective offenses."
  },
  {
    "objectID": "DS02Prezi.html#sql-use-how-insights-were-extracted",
    "href": "DS02Prezi.html#sql-use-how-insights-were-extracted",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "SQL Use – How Insights Were Extracted",
    "text": "SQL Use – How Insights Were Extracted\n\nSQL enabled efficient analysis across millions of rows:\n\nGrouped by race and stop outcomes\nFiltered out missing or irrelevant data\nCompared across cities to detect consistent patterns\n\nThe queries made the analysis transparent and reproducible"
  },
  {
    "objectID": "DS02Prezi.html#limitations",
    "href": "DS02Prezi.html#limitations",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Limitations",
    "text": "Limitations\n\nSome cities had incomplete records.\n\nDoesn’t show why decisions were made.\n\nWe see outcomes — not officer intent."
  },
  {
    "objectID": "DS02Prezi.html#conclusion",
    "href": "DS02Prezi.html#conclusion",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Conclusion",
    "text": "Conclusion\n\nRacial disparities are present in:\n\nSearch rates\nStop outcomes\nViolation types\n\nThese disparities vary by city, indicating room for policy-level intervention\nSQL and public data can support accountability and informed decision-making"
  },
  {
    "objectID": "DS02Prezi.html#thank-you",
    "href": "DS02Prezi.html#thank-you",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Thank You",
    "text": "Thank You"
  },
  {
    "objectID": "DS02Prezi.html#what-this-project-is-about",
    "href": "DS02Prezi.html#what-this-project-is-about",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "What This Project Is About",
    "text": "What This Project Is About\n\nI looked into how race affects traffic stop outcomes.\n\nUsed public data and SQL to explore search and arrest rates.\n\nThe goal: see if patterns show unfair treatment."
  },
  {
    "objectID": "DS02Prezi.html#the-data",
    "href": "DS02Prezi.html#the-data",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "The Data",
    "text": "The Data\n\nFrom the Stanford Open Policing Project (50M+ stops).\n\nI looked at three NC cities (Charlotte, Raleigh, Greensboro) and Oakland, CA.\n\nRemoved incomplete data to keep things clean and accurate."
  },
  {
    "objectID": "DS02Prezi.html#what-i-wanted-to-know",
    "href": "DS02Prezi.html#what-i-wanted-to-know",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "What I Wanted to Know",
    "text": "What I Wanted to Know\n\nWho gets searched more?\n\nWho’s more likely to be arrested or let go?\n\nDo the same gaps show up in different cities?"
  },
  {
    "objectID": "DS02Prezi.html#search-rates-by-race",
    "href": "DS02Prezi.html#search-rates-by-race",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Search Rates by Race",
    "text": "Search Rates by Race\n\nBlack and Hispanic drivers are searched more often than white drivers.\n\nIn many cities, disparities were consistent year-over-year."
  },
  {
    "objectID": "DS02Prezi.html#stop-outcome-results",
    "href": "DS02Prezi.html#stop-outcome-results",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Stop Outcome Results",
    "text": "Stop Outcome Results\n\nIn Oakland:\n\n52% of stops led to citations\n\n31% to warnings\n\n17% to arrests\n\n\nMost stops don’t end in arrest, but 1 in 6 still do — which stands out."
  },
  {
    "objectID": "DS02Prezi.html#slide-1-title-slide",
    "href": "DS02Prezi.html#slide-1-title-slide",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Slide 1: Title Slide",
    "text": "Slide 1: Title Slide\nExploring U.S. Policing Trends Through Data\nAn analysis of public data from multiple U.S. cities\nHenok Dawite\nMay 2025"
  },
  {
    "objectID": "DS02Prezi.html#slide-2-project-overview",
    "href": "DS02Prezi.html#slide-2-project-overview",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Slide 2: Project Overview",
    "text": "Slide 2: Project Overview\n\nThis project explores how traffic stops differ based on race.\n\nThe focus is on search rates and what happens after someone is pulled over.\n\nThe goal: help make sense of patterns that might point to bias in enforcement."
  },
  {
    "objectID": "DS02Prezi.html#slide-3-the-data",
    "href": "DS02Prezi.html#slide-3-the-data",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Slide 3: The Data",
    "text": "Slide 3: The Data\n\nSource: Stanford Open Policing Project (50M+ stops).\n\nFocused on cities with complete data: Charlotte, Raleigh, Greensboro, and Oakland.\n\nCleaned the data to keep only useful, consistent records."
  },
  {
    "objectID": "DS02Prezi.html#slide-4-key-questions",
    "href": "DS02Prezi.html#slide-4-key-questions",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Slide 4: Key Questions",
    "text": "Slide 4: Key Questions\n\nAre some racial groups searched more than others?\n\nDo stop outcomes (like arrest or warning) vary by race?\n\nAre these patterns the same across cities?"
  },
  {
    "objectID": "DS02Prezi.html#slide-5-search-rate-results",
    "href": "DS02Prezi.html#slide-5-search-rate-results",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Slide 5: Search Rate Results",
    "text": "Slide 5: Search Rate Results\n\n\nBlack drivers are searched more often than White drivers in every NC city analyzed.\n\nIn Charlotte: 6.75% (Black) vs 2.25% (White).\n\nThe same gap shows up in Raleigh and Greensboro."
  },
  {
    "objectID": "DS02Prezi.html#slide-6-stop-outcome-results",
    "href": "DS02Prezi.html#slide-6-stop-outcome-results",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Slide 6: Stop Outcome Results",
    "text": "Slide 6: Stop Outcome Results\n\n\nIn Oakland, most stops result in citations or warnings.\n\nBut about 1 in 6 ends in arrest — surprisingly high for traffic stops.\n\nThis raises questions about how enforcement power is used."
  },
  {
    "objectID": "DS02Prezi.html#slide-7-comparing-cities",
    "href": "DS02Prezi.html#slide-7-comparing-cities",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Slide 7: Comparing Cities",
    "text": "Slide 7: Comparing Cities\n\nWhile cities differ in stop rates, racial gaps stay consistent.\n\nBlack drivers are more likely to be searched or arrested across locations.\n\nThis points to something broader than just local policy."
  },
  {
    "objectID": "DS02Prezi.html#slide-8-how-the-work-was-done",
    "href": "DS02Prezi.html#slide-8-how-the-work-was-done",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Slide 8: How the Work Was Done",
    "text": "Slide 8: How the Work Was Done\n\nUsed SQL to filter and group data by race, outcome, and city.\n\nFocused on clarity and reproducibility — no complex models, just direct analysis.\n\nThe approach is transparent and can scale to other cities."
  },
  {
    "objectID": "DS02Prezi.html#slide-9-a-few-caveats",
    "href": "DS02Prezi.html#slide-9-a-few-caveats",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Slide 9: A Few Caveats",
    "text": "Slide 9: A Few Caveats\n\nSome cities had incomplete data and were excluded.\n\nThis analysis shows patterns, not causes.\n\nBut consistent outcomes across race suggest real disparities."
  },
  {
    "objectID": "DS02Prezi.html#slide-10-final-takeaway",
    "href": "DS02Prezi.html#slide-10-final-takeaway",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Slide 10: Final Takeaway",
    "text": "Slide 10: Final Takeaway\n\nThe data shows consistent racial gaps in both who gets searched and what happens after.\n\nThese patterns deserve attention and further investigation.\n\nOpen data and simple tools like SQL can help bring transparency to public systems"
  },
  {
    "objectID": "DS02Prezi.html#search-rate-results",
    "href": "DS02Prezi.html#search-rate-results",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Search Rate Results",
    "text": "Search Rate Results\n\nIn all three NC cities, Black drivers were searched more often than White drivers.\n\nCharlotte: 6.75% (Black) vs 2.25% (White).\n\nThis pattern was consistent across Raleigh and Greensboro too."
  },
  {
    "objectID": "DS02Prezi.html#comparing-cities",
    "href": "DS02Prezi.html#comparing-cities",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Comparing Cities",
    "text": "Comparing Cities\n\nWhile cities differ in stop rates, racial gaps stay consistent.\n\nBlack drivers are more likely to be searched or arrested across locations.\n\nThis points to something broader than just local policy."
  },
  {
    "objectID": "DS02Prezi.html#how-the-work-was-done",
    "href": "DS02Prezi.html#how-the-work-was-done",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "How the Work Was Done",
    "text": "How the Work Was Done\n\nUsed SQL to filter and group data by race, outcome, and city.\n\nFocused on clarity and reproducibility — no complex models, just direct analysis.\n\nThe approach is transparent and can scale to other cities."
  },
  {
    "objectID": "DS02Prezi.html#a-few-caveats",
    "href": "DS02Prezi.html#a-few-caveats",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "A Few Caveats",
    "text": "A Few Caveats\n\nSome cities had incomplete data and were excluded.\n\nThis analysis shows patterns, not causes.\n\nBut consistent outcomes across race suggest real disparities."
  },
  {
    "objectID": "DS02Prezi.html#final-takeaway",
    "href": "DS02Prezi.html#final-takeaway",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "Final Takeaway",
    "text": "Final Takeaway\n\nThe data shows real disparities in search rates across race.\n\nSimple analysis can bring out meaningful insights.\n\nPublic data like this is a powerful tool for accountability."
  },
  {
    "objectID": "DS02Prezi.html#what-i-looked-at",
    "href": "DS02Prezi.html#what-i-looked-at",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "What I Looked At",
    "text": "What I Looked At\n\nHow search rates compare by race across three NC cities.\n\nWhat the overall outcomes are after stops in Oakland.\n\nFocus was on identifying patterns — not proving intent or causation."
  },
  {
    "objectID": "DS02Prezi.html#what-the-patterns-suggest",
    "href": "DS02Prezi.html#what-the-patterns-suggest",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "What the Patterns Suggest",
    "text": "What the Patterns Suggest\n\nThe search data shows consistent gaps between racial groups.\n\nThe outcome data shows how often enforcement escalates to arrest.\n\nTogether, they highlight areas worth more attention and review."
  },
  {
    "objectID": "DS02Prezi.html#how-i-did-it",
    "href": "DS02Prezi.html#how-i-did-it",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "How I Did It",
    "text": "How I Did It\n\nI used SQL to group and filter the data.\n\nFocused on cities with full reporting to keep comparisons fair.\n\nThe approach was simple, clean, and easy to trace."
  },
  {
    "objectID": "DS02Prezi.html#a-few-notes",
    "href": "DS02Prezi.html#a-few-notes",
    "title": "Exploring U.S. Policing Trends Through Data",
    "section": "A Few Notes",
    "text": "A Few Notes\n\nI didn’t analyze outcomes by race — just overall rates.\n\nNot every city had usable data, so I narrowed the scope.\n\nThis project shows patterns — not causes."
  }
]